{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d227889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from data_loaders.dataloader3d import get_dataloader, load_data, MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_root(data):\n",
    "    #only after frames have been cut\n",
    "    root = (data[0,8,:]+data[0, 9, :])/2\n",
    "    data=np.delete((data - root), (1,8), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_frames(data):\n",
    "    \"\"\"\n",
    "    Drop frames where all 25 rows are identical.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Array with shape (frames, 25, 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Filtered array with duplicate frames removed\n",
    "    \"\"\"\n",
    "    first_row = data[:, 0:1, :]  # Shape: (frames, 1, 5)\n",
    "    all_rows_same = np.all(data == first_row, axis=(1,2))\n",
    "\n",
    "    mask = ~all_rows_same\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf76a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"data_example/700/vitpose_c1_a4_2/vitpose/keypoints_3d/smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98f657",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a,b \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmydataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypointtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmpl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\data_loaders\\dataloader3d.py:156\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(motion_path, split, keypointtype, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m keypointtype\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpose\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m keypointtype\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmpl\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    155\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(motion_path, patient, file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_subjects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_3d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmpl-keypoints-3d.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m     motion_clean\u001b[38;5;241m=\u001b[39m\u001b[43mload_pure_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmotion_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypointtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     no_orth_path \u001b[38;5;241m=\u001b[39m take[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_c2_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(take[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m    158\u001b[0m     file_path_wo \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(motion_path, patient, no_orth_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_subjects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_3d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmpl-keypoints-3d.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\data_loaders\\dataloader3d.py:42\u001b[0m, in \u001b[0;36mload_pure_keypoints\u001b[1;34m(keypointspath, motionlist, keypointtype)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#reshape to (frame, num_joints*3)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m keypoints\u001b[38;5;241m=\u001b[39mkeypoints[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 42\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m \u001b[43msubtract_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypointtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keypointtype\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpose\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     44\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m keypoints\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m23\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\data_loaders\\dataloader3d.py:31\u001b[0m, in \u001b[0;36msubtract_root\u001b[1;34m(data, keypointtype)\u001b[0m\n\u001b[0;32m     29\u001b[0m     root \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m     30\u001b[0m     data\u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m-\u001b[39m root\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m22\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown keypoint type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeypointtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a,b = load_data(\"mydataset\", split='train', keypointtype='6d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c4570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b422f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\n",
    "    dataset, \"train\", batch_size=2, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0a7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "<class 'data_loaders.dataloader3d.MotionDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of samples\n",
    "print(type(dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 135]) torch.Size([296, 135])\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0]\n",
    "print(img.shape, label.shape)  # shapes of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32bfde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 135])\n",
      "torch.Size([75, 135])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(a[i].shape)\n",
    "print(b[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e740148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\", a[2].numpy().reshape(-1, 24, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50150eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load: mydataset\\gait_682\\20250919_c2_a3_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a3_Take3\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a4_Take1\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a4_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a5_Take1\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a5_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Overall min and max values::\n",
      "-1.6090182703484142 0.38673450951507693\n",
      "-0.9003782868966556 0.8199114286130842\n",
      "-2.930964477812297 0.5061700658363381\n",
      "Shapes: 238 31\n"
     ]
    }
   ],
   "source": [
    "minx=5000\n",
    "maxx=-1000\n",
    "miny=5000\n",
    "maxy=-1000\n",
    "minz=5000\n",
    "maxz=-1000\n",
    "root=\"mydataset\"\n",
    "shapes=[]\n",
    "\n",
    "for patient in os.listdir(root):\n",
    "    for file in sorted(os.listdir(os.path.join(root, patient))):\n",
    "\n",
    "        mypath=os.path.join(root, patient, file)\n",
    "        mypath=os.path.join(mypath,\"split_subjects\", \"0\", \"keypoints_3d\", \"smpl-keypoints-3d_cut.npy\")\n",
    "        #print(mypath)\n",
    "        \n",
    "        try:\n",
    "            data=np.load(mypath)\n",
    "        except:\n",
    "            print(\"Could not load:\", mypath)    \n",
    "            continue\n",
    "        data=drop_duplicate_frames(data)\n",
    "        shapes.append(data.shape[0])\n",
    "        #print(data.shape)\n",
    "        data=subtract_root(data)\n",
    "        datax=data[...,0]\n",
    "        datay=data[...,1]\n",
    "        dataz=data[...,2]\n",
    "\n",
    "        curminx=np.min(datax)\n",
    "        curmaxx=np.max(datax)\n",
    "        curminy=np.min(datay)\n",
    "        curmaxy=np.max(datay)\n",
    "        curminz=np.min(dataz)\n",
    "        curmaxz=np.max(dataz)\n",
    "\n",
    "        if curminx < minx:\n",
    "            minx = curminx\n",
    "        if curmaxx > maxx:\n",
    "            maxx = curmaxx\n",
    "        if curminy < miny:\n",
    "            miny = curminy\n",
    "        if curmaxy > maxy:\n",
    "            maxy = curmaxy\n",
    "        if curminz < minz:\n",
    "            minz = curminz\n",
    "        if curmaxz > maxz:\n",
    "            maxz = curmaxz\n",
    "print(\"Overall min and max values::\")\n",
    "print(minx, maxx)\n",
    "print(miny, maxy)\n",
    "print(minz, maxz)\n",
    "print(\"Shapes:\", max(shapes), min(shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cfda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 25, 5)\n",
      "Keys inside: ['betas', 'global_orient', 'body_pose', 'transl', 'left_hand_pose', 'right_hand_pose', 'jaw_pose', 'leye_pose', 'reye_pose', 'expression']\n",
      "betas (53, 11)\n",
      "global_orient (53, 3)\n",
      "body_pose (53, 63)\n",
      "transl (53, 3)\n",
      "left_hand_pose (53, 12)\n",
      "right_hand_pose (53, 12)\n",
      "jaw_pose (53, 3)\n",
      "leye_pose (53, 3)\n",
      "reye_pose (53, 3)\n",
      "expression (53, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('mydataset/gait_753/20250617_c1_a2_Take1/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy')\n",
    "print(data.shape)\n",
    "data= np.load('mydataset/gait_753/20250617_c1_a2_Take1/split_subjects/0/fit-smplx/smplx-params.npz')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa5f30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('mydataset/gait_390\\\\20251016_c1_a1_Take1\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bdef4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 25, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baefc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49295893,  1.69739822,  1.18428878,  1.        ,  0.87212847],\n",
       "       [-0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.67501091,  1.55301859,  1.27222228,  1.        ,  0.81018223],\n",
       "       [ 0.75312366,  1.31790896,  1.25361495,  1.        ,  0.81621757],\n",
       "       [ 0.78419439,  1.14389381,  1.12778531,  1.        ,  0.78943297],\n",
       "       [ 0.44118821,  1.57517521,  1.36380837,  1.        ,  0.79012868],\n",
       "       [ 0.4006466 ,  1.36783878,  1.4289626 ,  1.        ,  0.73623571],\n",
       "       [ 0.34845147,  1.17217453,  1.44956488,  1.        ,  0.71890461],\n",
       "       [ 0.49215891,  1.11726584,  1.40670784,  1.        ,  0.72314226],\n",
       "       [ 0.6580688 ,  1.10928205,  1.35557747,  1.        ,  0.7100429 ],\n",
       "       [ 0.65657013,  0.75494605,  1.39977121,  1.        ,  0.74219274],\n",
       "       [ 0.64947111,  0.4334592 ,  1.42931163,  1.        ,  0.73011186],\n",
       "       [ 0.49215891,  1.11726584,  1.40670784,  1.        ,  0.72314226],\n",
       "       [ 0.44884126,  0.78639402,  1.26389243,  1.        ,  0.77846177],\n",
       "       [ 0.43275981,  0.41424928,  1.21718529,  1.        ,  0.79570626],\n",
       "       [ 0.51782129,  1.72689032,  1.17947589,  1.        ,  0.86403344],\n",
       "       [ 0.47256139,  1.72659763,  1.20193305,  1.        ,  0.8622156 ],\n",
       "       [ 0.59784739,  1.72953696,  1.21963715,  1.        ,  0.81688168],\n",
       "       [ 0.45389005,  1.73149812,  1.28395713,  1.        ,  0.77243718],\n",
       "       [ 0.37236532,  0.38123661,  1.05549675,  1.        ,  0.800674  ],\n",
       "       [ 0.34539783,  0.37998719,  1.10221369,  1.        ,  0.79264247],\n",
       "       [ 0.4536038 ,  0.36271161,  1.24054489,  1.        ,  0.79869173],\n",
       "       [ 0.6056103 ,  0.37457891,  1.29649016,  1.        ,  0.76701352],\n",
       "       [ 0.65184898,  0.37947832,  1.31626623,  1.        ,  0.76794479],\n",
       "       [ 0.64764808,  0.38522647,  1.46748305,  1.        ,  0.695054  ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformation_sixd import smplx_to_6d, sixd_to_smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de05fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=smplx_to_6d(\"mydataset\\\\740\\\\20251002_c1_a1_Take1\\\\split_subjects\\\\0\\\\fit-smplx\\\\smplx-params.npz\", \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6185b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\utils\\utils_transform.py:54: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  rot_vec_3 = torch.cross(rot_vec_1, rot_vec_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing forward kinematics to calculate joint positions...\n",
      "Using generic SMPL-X model for forward kinematics.\n",
      "Extracting joints for 109 frames...\n",
      "\n",
      "Successfully reconstructed 3D keypoints.\n",
      "Output shape: (109, 22, 3)\n",
      "Saved result to: test/reconstructed_keypoints_3d_ref.npy\n"
     ]
    }
   ],
   "source": [
    "sixd_to_smplx(\"test/motion_6d_with_transl.npz\", \"test/\", \"smpl_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc0cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"012314.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9195c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 22, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_keypoints_only_mask(keypoints_path, height_thresh=0.03, vel_thresh=0.05, video_fps=30):\n",
    "    \"\"\"\n",
    "    Determines foot contact purely from kinematics (Keypoints), ignoring the Force Plate.\n",
    "    \n",
    "    Criteria for Contact:\n",
    "    1. Height: Joint Y-coordinate is close to the ground floor.\n",
    "    2. Velocity: Joint is not moving significantly (Stance phase is static).\n",
    "\n",
    "    Args:\n",
    "        keypoints_path (str): Path to .npy keypoints (frames, 25, 3).\n",
    "        height_thresh (float): Max distance from floor (e.g., 0.03m).\n",
    "        vel_thresh (float): Max velocity to be considered \"static\" (e.g., 0.05 m/frame).\n",
    "        video_fps (int): Video frame rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask of shape (frames, 25).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        keypoints = np.load(keypoints_path) # Shape (F, 25, 3)\n",
    "        n_frames = keypoints.shape[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Calculate the Floor (Ground Truth)\n",
    "    # We assume the lowest 5% of ALL foot points in the entire file represent the floor.\n",
    "    # This is robust to outliers.\n",
    "    foot_indices = [19, 20, 21, 22, 23, 24] # L/R BigToe, SmallToe, Heel\n",
    "    all_foot_y = keypoints[:, foot_indices, 1]\n",
    "    \n",
    "    # Filter out zeros (undetected points)\n",
    "    valid_y = all_foot_y[all_foot_y != 0]\n",
    "    if len(valid_y) == 0:\n",
    "        print(\"No valid foot keypoints found.\")\n",
    "        return np.zeros((n_frames, 25), dtype=int)\n",
    "        \n",
    "    floor_level = np.percentile(valid_y, 5) # 5th percentile is the estimated floor\n",
    "    print(f\"Auto-detected Floor Level: {floor_level:.4f}\")\n",
    "\n",
    "    velocity = np.linalg.norm(np.diff(keypoints, axis=0, prepend=keypoints[0:1]), axis=2)\n",
    "    \n",
    "    is_low = keypoints[:, :, 1] < (floor_level + height_thresh)\n",
    "\n",
    "    is_static = velocity < vel_thresh\n",
    "    \n",
    "    is_detected = keypoints[:, :, 1] != 0\n",
    "\n",
    "    contact_mask = is_low & is_static & is_detected\n",
    "\n",
    "    final_mask = np.zeros_like(contact_mask, dtype=int)\n",
    "    final_mask[:, foot_indices] = contact_mask[:, foot_indices].astype(int)\n",
    "\n",
    "    return final_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4686e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected Floor Level: 0.3254\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "path=\"mydataset/740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "mask = generate_keypoints_only_mask(path, height_thresh=0.03, vel_thresh=0.04)\n",
    "data=np.load(path)\n",
    "masked_data = data * mask[:, :, np.newaxis]\n",
    "np.save('masked_keypoints.npy', masked_data)\n",
    "print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4171b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"mydataset/gait_740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "data=np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89df11ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7469546 ,  1.70051745,  1.47945776,  1.        ,  0.87591164],\n",
       "       [-0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.89867985,  1.54275708,  1.4916359 ,  1.        ,  0.7950817 ],\n",
       "       [ 0.92574996,  1.29225018,  1.48549268,  1.        ,  0.76842021],\n",
       "       [ 0.83637742,  1.13856328,  1.39925742,  1.        ,  0.83004757],\n",
       "       [ 0.71709629,  1.54149615,  1.67466774,  1.        ,  0.82468709],\n",
       "       [ 0.70413344,  1.30393124,  1.73593169,  1.        ,  0.76897747],\n",
       "       [ 0.66937562,  1.10709913,  1.68101669,  1.        ,  0.79215371],\n",
       "       [ 0.75413956,  1.1012916 ,  1.67303916,  1.        ,  0.75339102],\n",
       "       [ 0.87500368,  1.0986548 ,  1.57471008,  1.        ,  0.72355129],\n",
       "       [ 0.82541505,  0.77695421,  1.57627764,  1.        ,  0.8144853 ],\n",
       "       [ 0.80412727,  0.46680547,  1.55428712,  1.        ,  0.79213246],\n",
       "       [ 0.75413956,  1.1012916 ,  1.67303916,  1.        ,  0.75339102],\n",
       "       [ 0.6848366 ,  0.80046247,  1.57926683,  1.        ,  0.83255949],\n",
       "       [ 0.66877012,  0.44811671,  1.53452882,  1.        ,  0.84502734],\n",
       "       [ 0.76843799,  1.73521875,  1.47207144,  1.        ,  0.8712836 ],\n",
       "       [ 0.72696876,  1.73071009,  1.5022468 ,  1.        ,  0.86694657],\n",
       "       [ 0.83776099,  1.73458002,  1.49701491,  1.        ,  0.81093989],\n",
       "       [ 0.72137754,  1.72606506,  1.59972631,  1.        ,  0.87431749],\n",
       "       [ 0.58096945,  0.41418493,  1.39736453,  1.        ,  0.79025819],\n",
       "       [ 0.56663332,  0.41371249,  1.44821907,  1.        ,  0.79651313],\n",
       "       [ 0.69671089,  0.40045008,  1.5524462 ,  1.        ,  0.80519178],\n",
       "       [ 0.73776713,  0.4260078 ,  1.41754528,  1.        ,  0.79692181],\n",
       "       [ 0.77912289,  0.4280605 ,  1.42099141,  1.        ,  0.78808818],\n",
       "       [ 0.80705967,  0.42860119,  1.58168915,  1.        ,  0.7485457 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbcbb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.delete(data, (1,8), axis=1)  # remove the second joint (index 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe05c650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 23, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e8f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c8dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_transformation_matrix(v):\n",
    "    \"\"\"\n",
    "    Creates a matrix that rotates v to the X-axis, mirrors Z, \n",
    "    and rotates back.\n",
    "    \"\"\"\n",
    "    # 1. Define input and target\n",
    "    v = np.array(v, dtype=float)\n",
    "    target = np.array([1, 0, 0], dtype=float)\n",
    "    \n",
    "    # Normalize input\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v == 0: return np.eye(3)\n",
    "    a = v / norm_v\n",
    "    b = target\n",
    "\n",
    "    # 2. Compute Rotation (Rodrigues' Formula)\n",
    "    # Axis of rotation (k)\n",
    "    k = np.cross(a, b)\n",
    "    s = np.linalg.norm(k) # sin of angle\n",
    "    c = np.dot(a, b)      # cos of angle\n",
    "\n",
    "    if s == 0:\n",
    "        # Vector is already on x-axis (parallel)\n",
    "        if c > 0: return np.diag([1, 1, -1]) # Just mirror\n",
    "        # If anti-parallel (-x), we usually just flip indices, \n",
    "        # but technically needs 180 rotation. Simplified here:\n",
    "        return np.diag([1, 1, -1]) \n",
    "\n",
    "    # Skew-symmetric matrix K\n",
    "    K = np.array([\n",
    "        [0, -k[2], k[1]],\n",
    "        [k[2], 0, -k[0]],\n",
    "        [-k[1], k[0], 0]\n",
    "    ])\n",
    "\n",
    "    # Rotation Matrix (aligns v -> x)\n",
    "    # Note: We want R that takes v to x. \n",
    "    # The formula R = I + K + ... rotates a to b.\n",
    "    R = np.eye(3) + K + (K @ K) * ((1 - c) / (s**2))\n",
    "\n",
    "    # 3. Mirror Matrix (Mirror across XY plane means Z -> -Z)\n",
    "    M = np.diag([1, 1, -1])\n",
    "\n",
    "    # 4. Combine: Un-rotate * Mirror * Rotate\n",
    "    # Note: If R takes v->x, then R.T takes x->v.\n",
    "    # Order depends on if we view R as transforming the basis or the vector.\n",
    "    # Standard: T_final = R.T @ M @ R\n",
    "    return R.T @ M @ R\n",
    "\n",
    "# --- Usage ---\n",
    "input_vector = [1, 1, 1] # The vector defining the orientation\n",
    "points_to_transform = [\n",
    "    [2, 2, 2],\n",
    "    [0, 5, 0],\n",
    "    [1, 1, 1]\n",
    "]\n",
    "\n",
    "transform_matrix = get_transformation_matrix(input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b4ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"mydataset/gait_753\\\\20250617_c2_a3_Take2\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7dabc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=data[0,2,:]+data[0, 5, :]/2\n",
    "dest=data[20,2,:]+data[20, 5, :]/2\n",
    "vec=dest - root\n",
    "vec=vec[:3]\n",
    "transform_matrix = get_transformation_matrix(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b66dea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = data[..., :3] @ transform_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb9cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[..., :3] = transformed_data\n",
    "np.save(\"mydataset/gait_753\\\\20250617_c2_a3_Take2\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6a2dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"mydataset/gait_753\\\\20250617_c2_a3_Take2\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut_aligned.npy\", np.load(\"mydataset/gait_753\\\\20250617_c2_a3_Take2\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
