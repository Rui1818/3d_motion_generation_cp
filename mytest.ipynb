{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d227889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from data_loaders.dataloader3d import get_dataloader, load_data, MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_root(data):\n",
    "    #only after frames have been cut\n",
    "    root = (data[0,8,:]+data[0, 9, :])/2\n",
    "    return data - root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_frames(data):\n",
    "    \"\"\"\n",
    "    Drop frames where all 25 rows are identical.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Array with shape (frames, 25, 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Filtered array with duplicate frames removed\n",
    "    \"\"\"\n",
    "    first_row = data[:, 0:1, :]  # Shape: (frames, 1, 5)\n",
    "    all_rows_same = np.all(data == first_row, axis=(1,2))\n",
    "\n",
    "    mask = ~all_rows_same\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf76a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"data_example/700/vitpose_c1_a4_2/vitpose/keypoints_3d/smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a98f657",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a,b \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmydataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypointtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m6d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\data_loaders\\dataloader3d.py:136\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(motion_path, split, mode, keypointtype, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keypointtype\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    135\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(motion_path, patient, file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_subjects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit-smplx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmplx-params.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m     motion_clean\u001b[38;5;241m=\u001b[39m\u001b[43mload_6drotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmotion_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     no_orth_path \u001b[38;5;241m=\u001b[39m take[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_c2_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(take[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m    138\u001b[0m     file_path_wo \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(motion_path, patient, no_orth_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_subjects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit-smplx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmplx-params.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\data_loaders\\dataloader3d.py:41\u001b[0m, in \u001b[0;36mload_6drotations\u001b[1;34m(motion_6dpath, motionlist)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_6drotations\u001b[39m(motion_6dpath, motionlist):\n\u001b[0;32m     40\u001b[0m     motion_6d, transl, _ \u001b[38;5;241m=\u001b[39m smplx_to_6d(motion_6dpath) \u001b[38;5;66;03m#shape (frames, 132), (frames, 3), (frames, 11)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     motion_6d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmotion_6d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     transl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(transl, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     43\u001b[0m     result\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat((motion_6d, transl), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m#shape (frames, 135)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "a,b = load_data(\"mydataset\", split='train', keypointtype='6d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c4570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b422f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\n",
    "    dataset, \"train\", batch_size=2, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0a7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'data_loaders.dataloader3d.MotionDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of samples\n",
    "print(type(dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 72]) torch.Size([296, 72])\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0]\n",
    "print(img.shape, label.shape)  # shapes of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32bfde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([286, 72])\n",
      "torch.Size([215, 72])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(a[i].shape)\n",
    "print(b[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e740148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\", a[2].numpy().reshape(-1, 24, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50150eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations\\753\\vitpose_c1_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(96, 25, 5)\n",
      "observations\\753\\vitpose_c1_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(98, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(78, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(70, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(277, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(122, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(164, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(359, 25, 5)\n",
      "(286, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(182, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(72, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(58, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(139, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(166, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(221, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(48, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(144, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(215, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(273, 25, 5)\n",
      "Overall min and max values:\n",
      "-0.8759354218465447 0.975103836792062\n",
      "-0.022 1.2910989693513175\n",
      "-1.8723811722336592 1.8882560870466816\n"
     ]
    }
   ],
   "source": [
    "minx=5000\n",
    "maxx=-1000\n",
    "miny=5000\n",
    "maxy=-1000\n",
    "minz=5000\n",
    "maxz=-1000\n",
    "root=\"observations\"\n",
    "\n",
    "for patient in os.listdir(root):\n",
    "    for file in sorted(os.listdir(os.path.join(root, patient))):\n",
    "\n",
    "        mypath=os.path.join(root, patient, file)\n",
    "        mypath=os.path.join(mypath,\"vitpose\", \"keypoints_3d\", \"smpl-keypoints-3d_cut.npy\")\n",
    "        print(mypath)\n",
    "        data=np.load(mypath)\n",
    "        print(data.shape)   \n",
    "        data=drop_duplicate_frames(data)\n",
    "        print(data.shape)\n",
    "        datax=data[...,0]\n",
    "        datay=data[...,1]\n",
    "        dataz=data[...,2]\n",
    "        data=subtract_root(data)\n",
    "\n",
    "        curminx=np.min(datax)\n",
    "        curmaxx=np.max(datax)\n",
    "        curminy=np.min(datay)\n",
    "        curmaxy=np.max(datay)\n",
    "        curminz=np.min(dataz)\n",
    "        curmaxz=np.max(dataz)\n",
    "\n",
    "        if curminx < minx:\n",
    "            minx = curminx\n",
    "        if curmaxx > maxx:\n",
    "            maxx = curmaxx\n",
    "        if curminy < miny:\n",
    "            miny = curminy\n",
    "        if curmaxy > maxy:\n",
    "            maxy = curmaxy\n",
    "        if curminz < minz:\n",
    "            minz = curminz\n",
    "        if curmaxz > maxz:\n",
    "            maxz = curmaxz\n",
    "print(\"Overall min and max values:\")\n",
    "print(minx, maxx)\n",
    "print(miny, maxy)\n",
    "print(minz, maxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cfda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys inside: ['betas', 'global_orient', 'body_pose', 'transl', 'left_hand_pose', 'right_hand_pose', 'jaw_pose', 'leye_pose', 'reye_pose', 'expression']\n",
      "betas (88, 11)\n",
      "global_orient (88, 3)\n",
      "body_pose (88, 63)\n",
      "transl (88, 3)\n",
      "left_hand_pose (88, 12)\n",
      "right_hand_pose (88, 12)\n",
      "jaw_pose (88, 3)\n",
      "leye_pose (88, 3)\n",
      "reye_pose (88, 3)\n",
      "expression (88, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('0\\\\fit-smplx\\\\smplx-params.npz')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5f30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('0\\\\keypoints_3d\\\\smpl-keypoints-3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdef4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 25, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformation_sixd import smplx_to_6d, sixd_to_smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=smplx_to_6d(\"mydataset\\\\740\\\\20251002_c1_a1_Take1\\\\split_subjects\\\\0\\\\fit-smplx\\\\smplx-params.npz\", \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6185b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\utils\\utils_transform.py:54: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  rot_vec_3 = torch.cross(rot_vec_1, rot_vec_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing forward kinematics to calculate joint positions...\n",
      "Using kid template for SMPL-X model forward kinematics.\n",
      "Extracting joints for 109 frames...\n",
      "\n",
      "Successfully reconstructed 3D keypoints.\n",
      "Output shape: (109, 22, 3)\n",
      "Saved result to: test/reconstructed_keypoints_3d.npy\n"
     ]
    }
   ],
   "source": [
    "sixd_to_smplx(\"test/motion_6d_with_transl.npz\", \"test/\", \"smpl_models/\", \"smpl_models/smplx/smplx_kid_template.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc0cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"test/motion_6d_with_transl.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1517bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transl'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab4858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 132)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['motion_6d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beacf061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'betas' in data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
