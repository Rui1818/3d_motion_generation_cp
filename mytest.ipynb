{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d227889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from data_loaders.dataloader3d import get_dataloader, load_data, MotionDataset, TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c924bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "814a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_root(data):\n",
    "    #only after frames have been cut\n",
    "    root = (data[0,8,:]+data[0, 9, :])/2\n",
    "    data=np.delete((data - root), (1,8), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6a58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_frames(data):\n",
    "    \"\"\"\n",
    "    Drop frames where all 25 rows are identical.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Array with shape (frames, 25, 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Filtered array with duplicate frames removed\n",
    "    \"\"\"\n",
    "    first_row = data[:, 0:1, :]  # Shape: (frames, 1, 5)\n",
    "    all_rows_same = np.all(data == first_row, axis=(1,2))\n",
    "\n",
    "    mask = ~all_rows_same\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a98f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a,b = load_data(\"mydataset\", split='train', keypointtype='openpose')\n",
    "a,b,c = load_data(\"test_dataset\", split='test', keypointtype='openpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5c6a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a[\u001b[38;5;241m0\u001b[39m], b[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, \u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a[0].shape, b[0].shape, c[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44cf036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TestDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    betas=c,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c4570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223637b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b422f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\n",
    "    dataset, \"train\", batch_size=1, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0a7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "<class 'data_loaders.dataloader3d.TestDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of samples\n",
    "print(type(dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a83cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 135]) torch.Size([296, 135]) (82, 11)\n"
     ]
    }
   ],
   "source": [
    "img, label, betas = dataset[7]\n",
    "print(img.shape, label.shape, betas.shape)  # shapes of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9905fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 296, 135]) torch.Size([1, 296, 135]) torch.Size([1, 82, 11])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    images, labels,betas = batch\n",
    "    print(images.shape, labels.shape, betas.shape)  # shapes of the batch\n",
    "    break  # Just process the first batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 135])\n",
      "torch.Size([75, 135])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(a[i].shape)\n",
    "print(b[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50150eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load: mydataset\\gait_682\\20250919_c2_a3_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a3_Take3\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a4_Take1\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a4_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a5_Take1\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Could not load: mydataset\\gait_682\\20250919_c2_a5_Take2\\split_subjects\\0\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "Overall min and max values::\n",
      "-1.6090182703484142 0.38673450951507693\n",
      "-0.9003782868966556 0.8199114286130842\n",
      "-2.930964477812297 0.5061700658363381\n",
      "Shapes: 238 31\n"
     ]
    }
   ],
   "source": [
    "minx=5000\n",
    "maxx=-1000\n",
    "miny=5000\n",
    "maxy=-1000\n",
    "minz=5000\n",
    "maxz=-1000\n",
    "root=\"mydataset\"\n",
    "shapes=[]\n",
    "\n",
    "for patient in os.listdir(root):\n",
    "    for file in sorted(os.listdir(os.path.join(root, patient))):\n",
    "\n",
    "        mypath=os.path.join(root, patient, file)\n",
    "        mypath=os.path.join(mypath,\"split_subjects\", \"0\", \"keypoints_3d\", \"smpl-keypoints-3d_cut.npy\")\n",
    "        #print(mypath)\n",
    "        \n",
    "        try:\n",
    "            data=np.load(mypath)\n",
    "        except:\n",
    "            print(\"Could not load:\", mypath)    \n",
    "            continue\n",
    "        data=drop_duplicate_frames(data)\n",
    "        shapes.append(data.shape[0])\n",
    "        #print(data.shape)\n",
    "        data=subtract_root(data)\n",
    "        datax=data[...,0]\n",
    "        datay=data[...,1]\n",
    "        dataz=data[...,2]\n",
    "\n",
    "        curminx=np.min(datax)\n",
    "        curmaxx=np.max(datax)\n",
    "        curminy=np.min(datay)\n",
    "        curmaxy=np.max(datay)\n",
    "        curminz=np.min(dataz)\n",
    "        curmaxz=np.max(dataz)\n",
    "\n",
    "        if curminx < minx:\n",
    "            minx = curminx\n",
    "        if curmaxx > maxx:\n",
    "            maxx = curmaxx\n",
    "        if curminy < miny:\n",
    "            miny = curminy\n",
    "        if curmaxy > maxy:\n",
    "            maxy = curmaxy\n",
    "        if curminz < minz:\n",
    "            minz = curminz\n",
    "        if curmaxz > maxz:\n",
    "            maxz = curmaxz\n",
    "print(\"Overall min and max values::\")\n",
    "print(minx, maxx)\n",
    "print(miny, maxy)\n",
    "print(minz, maxz)\n",
    "print(\"Shapes:\", max(shapes), min(shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cfda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 25, 5)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmydataset/gait_753/20250617_c1_a1_Take1/split_subjects/0/fit-smplx/smpl-keypoints-3d_cut.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys inside:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mfiles:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, data[k]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'files'"
     ]
    }
   ],
   "source": [
    "data = np.load('mydataset/gait_753/20250617_c1_a2_Take1/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy')\n",
    "print(data.shape)\n",
    "data= np.load('mydataset/gait_753/20250617_c1_a1_Take1/split_subjects/0/fit-smplx/smpl-keypoints-3d_cut.npy')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad979f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys inside: ['betas', 'global_orient', 'body_pose', 'transl', 'left_hand_pose', 'right_hand_pose', 'jaw_pose', 'leye_pose', 'reye_pose', 'expression']\n",
      "betas (121, 10)\n",
      "global_orient (121, 3)\n",
      "body_pose (121, 63)\n",
      "transl (121, 3)\n",
      "left_hand_pose (121, 12)\n",
      "right_hand_pose (121, 12)\n",
      "jaw_pose (121, 3)\n",
      "leye_pose (121, 3)\n",
      "reye_pose (121, 3)\n",
      "expression (121, 10)\n"
     ]
    }
   ],
   "source": [
    "data= np.load('mydataset/gait_700/20250820_c1_a1_Take1/split_subjects/0/fit-smplx/smplx-params.npz')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0b484b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 69)\n"
     ]
    }
   ],
   "source": [
    "data= np.load('results/generated_motion_0.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformation_sixd import smplx_to_6d, sixd_to_smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=smplx_to_6d(\"mydataset\\\\740\\\\20251002_c1_a1_Take1\\\\split_subjects\\\\0\\\\fit-smplx\\\\smplx-params.npz\", \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\utils\\utils_transform.py:54: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  rot_vec_3 = torch.cross(rot_vec_1, rot_vec_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing forward kinematics to calculate joint positions...\n",
      "Using generic SMPL-X model for forward kinematics.\n",
      "Extracting joints for 109 frames...\n",
      "\n",
      "Successfully reconstructed 3D keypoints.\n",
      "Output shape: (109, 22, 3)\n",
      "Saved result to: test/reconstructed_keypoints_3d_ref.npy\n"
     ]
    }
   ],
   "source": [
    "sixd_to_smplx(\"test/motion_6d_with_transl.npz\", \"test/\", \"smpl_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"012314.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9195c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 22, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_keypoints_only_mask(keypoints_path, height_thresh=0.03, vel_thresh=0.05, video_fps=30):\n",
    "    \"\"\"\n",
    "    Determines foot contact purely from kinematics (Keypoints), ignoring the Force Plate.\n",
    "    \n",
    "    Criteria for Contact:\n",
    "    1. Height: Joint Y-coordinate is close to the ground floor.\n",
    "    2. Velocity: Joint is not moving significantly (Stance phase is static).\n",
    "\n",
    "    Args:\n",
    "        keypoints_path (str): Path to .npy keypoints (frames, 25, 3).\n",
    "        height_thresh (float): Max distance from floor (e.g., 0.03m).\n",
    "        vel_thresh (float): Max velocity to be considered \"static\" (e.g., 0.05 m/frame).\n",
    "        video_fps (int): Video frame rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask of shape (frames, 25).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        keypoints = np.load(keypoints_path) # Shape (F, 25, 3)\n",
    "        n_frames = keypoints.shape[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Calculate the Floor (Ground Truth)\n",
    "    # We assume the lowest 5% of ALL foot points in the entire file represent the floor.\n",
    "    # This is robust to outliers.\n",
    "    foot_indices = [19, 20, 21, 22, 23, 24] # L/R BigToe, SmallToe, Heel\n",
    "    all_foot_y = keypoints[:, foot_indices, 1]\n",
    "    \n",
    "    # Filter out zeros (undetected points)\n",
    "    valid_y = all_foot_y[all_foot_y != 0]\n",
    "    if len(valid_y) == 0:\n",
    "        print(\"No valid foot keypoints found.\")\n",
    "        return np.zeros((n_frames, 25), dtype=int)\n",
    "        \n",
    "    floor_level = np.percentile(valid_y, 5) # 5th percentile is the estimated floor\n",
    "    print(f\"Auto-detected Floor Level: {floor_level:.4f}\")\n",
    "\n",
    "    velocity = np.linalg.norm(np.diff(keypoints, axis=0, prepend=keypoints[0:1]), axis=2)\n",
    "    \n",
    "    is_low = keypoints[:, :, 1] < (floor_level + height_thresh)\n",
    "\n",
    "    is_static = velocity < vel_thresh\n",
    "    \n",
    "    is_detected = keypoints[:, :, 1] != 0\n",
    "\n",
    "    contact_mask = is_low & is_static & is_detected\n",
    "\n",
    "    final_mask = np.zeros_like(contact_mask, dtype=int)\n",
    "    final_mask[:, foot_indices] = contact_mask[:, foot_indices].astype(int)\n",
    "\n",
    "    return final_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4686e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected Floor Level: 0.3254\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "path=\"mydataset/740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "mask = generate_keypoints_only_mask(path, height_thresh=0.03, vel_thresh=0.04)\n",
    "data=np.load(path)\n",
    "masked_data = data * mask[:, :, np.newaxis]\n",
    "np.save('masked_keypoints.npy', masked_data)\n",
    "print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"mydataset/gait_740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "data=np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.delete(data, (1,8), axis=1)  # remove the second joint (index 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05c650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 23, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e8f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_transformation_matrix(v):\n",
    "    \"\"\"\n",
    "    Creates a matrix that rotates v to the X-axis, mirrors Z, \n",
    "    and rotates back.\n",
    "    \"\"\"\n",
    "    # 1. Define input and target\n",
    "    v = np.array(v, dtype=float)\n",
    "    target = np.array([1, 0, 0], dtype=float)\n",
    "    \n",
    "    # Normalize input\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v == 0: return np.eye(3)\n",
    "    a = v / norm_v\n",
    "    b = target\n",
    "\n",
    "    # 2. Compute Rotation (Rodrigues' Formula)\n",
    "    # Axis of rotation (k)\n",
    "    k = np.cross(a, b)\n",
    "    s = np.linalg.norm(k) # sin of angle\n",
    "    c = np.dot(a, b)      # cos of angle\n",
    "\n",
    "    if s == 0:\n",
    "        # Vector is already on x-axis (parallel)\n",
    "        if c > 0: return np.diag([1, 1, -1]) # Just mirror\n",
    "        # If anti-parallel (-x), we usually just flip indices, \n",
    "        # but technically needs 180 rotation. Simplified here:\n",
    "        return np.diag([1, 1, -1]) \n",
    "\n",
    "    # Skew-symmetric matrix K\n",
    "    K = np.array([\n",
    "        [0, -k[2], k[1]],\n",
    "        [k[2], 0, -k[0]],\n",
    "        [-k[1], k[0], 0]\n",
    "    ])\n",
    "\n",
    "    # Rotation Matrix (aligns v -> x)\n",
    "    # Note: We want R that takes v to x. \n",
    "    # The formula R = I + K + ... rotates a to b.\n",
    "    R = np.eye(3) + K + (K @ K) * ((1 - c) / (s**2))\n",
    "\n",
    "    # 3. Mirror Matrix (Mirror across XY plane means Z -> -Z)\n",
    "    M = np.diag([1, 1, -1])\n",
    "\n",
    "    # 4. Combine: Un-rotate * Mirror * Rotate\n",
    "    # Note: If R takes v->x, then R.T takes x->v.\n",
    "    # Order depends on if we view R as transforming the basis or the vector.\n",
    "    # Standard: T_final = R.T @ M @ R\n",
    "    return R.T @ M @ R\n",
    "\n",
    "# --- Usage ---\n",
    "input_vector = [1, 1, 1] # The vector defining the orientation\n",
    "points_to_transform = [\n",
    "    [2, 2, 2],\n",
    "    [0, 5, 0],\n",
    "    [1, 1, 1]\n",
    "]\n",
    "\n",
    "transform_matrix = get_transformation_matrix(input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49b4ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"mydataset/gait_766\\\\20251001_c2_a3_Take3\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7dabc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=data[0,2,:]+data[0, 5, :]/2\n",
    "dest=data[44,2,:]+data[44, 5, :]/2\n",
    "vec=dest - root\n",
    "vec=vec[:3]\n",
    "transform_matrix = get_transformation_matrix(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b66dea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = data[..., :3] @ transform_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cb9cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[..., :3] = transformed_data\n",
    "np.save(\"mydataset/gait_766\\\\20251001_c2_a3_Take3\\\\split_subjects\\\\0\\\\keypoints_3d\\\\smpl-keypoints-3d_cut.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7c1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10075223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def rotate_smplx_params_y_180(smplx_path: str):\n",
    "    \"\"\"\n",
    "    Loads an SMPL-X parameters file, rotates the global orientation and translation\n",
    "    180 degrees around the Y-axis, and saves the result back to the file.\n",
    "\n",
    "    Args:\n",
    "        smplx_path (str): Path to the .npz or .npy file containing the dictionary \n",
    "                          of SMPL-X parameters.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(smplx_path):\n",
    "        print(f\"Error: File not found at '{smplx_path}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading SMPL-X params from: {smplx_path}\")\n",
    "    \n",
    "    # Load the data\n",
    "    # allow_pickle is needed if the .npy contains a dictionary object\n",
    "    data = np.load(smplx_path, allow_pickle=True)\n",
    "    \n",
    "    # Convert to a mutable dictionary based on file type\n",
    "    if isinstance(data, np.lib.npyio.NpzFile):\n",
    "        # If it's a .npz (zipped), convert to dict\n",
    "        params = dict(data)\n",
    "    elif data.ndim == 0 and data.dtype == 'O':\n",
    "        # If it's a 0-d array wrapping a dict (common in some datasets)\n",
    "        params = data.item()\n",
    "    else:\n",
    "        # If it's already a dict or structured array\n",
    "        params = dict(data)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Rotate Translation (transl)\n",
    "    # ---------------------------------------------------------\n",
    "    if 'transl' in params:\n",
    "        # Transformation: (x, y, z) -> (-x, y, -z)\n",
    "        # We multiply x and z by -1\n",
    "        transl = params['transl'].copy()\n",
    "        transl[:, 0] *= -1  # Invert X\n",
    "        transl[:, 2] *= -1  # Invert Z\n",
    "        params['transl'] = transl\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Rotate Global Orientation (global_orient)\n",
    "    # ---------------------------------------------------------\n",
    "    if 'global_orient' in params:\n",
    "        global_orient = params['global_orient'] # Shape (N, 3) - Axis Angle\n",
    "        \n",
    "        # Convert current axis-angle to Rotation object\n",
    "        rot_original = R.from_rotvec(global_orient)\n",
    "        \n",
    "        # Create a 180-degree rotation around Y-axis\n",
    "        rot_180_y = R.from_euler('y', 180, degrees=True)\n",
    "        \n",
    "        # Apply the rotation: New = Rot180 * Old\n",
    "        # (We left-multiply to apply the rotation to the global frame)\n",
    "        rot_new = rot_180_y * rot_original\n",
    "        \n",
    "        # Convert back to axis-angle and ensure correct datatype\n",
    "        params['global_orient'] = rot_new.as_rotvec().astype(global_orient.dtype)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Save Output\n",
    "    # ---------------------------------------------------------\n",
    "    base_path, ext = os.path.splitext(smplx_path)\n",
    "    \n",
    "    if ext == '.npz':\n",
    "        np.savez(smplx_path, **params)\n",
    "    else:\n",
    "        np.save(smplx_path, params)\n",
    "        \n",
    "    print(f\" -> Modified and saved to: {smplx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad015d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SMPL-X params from: mydataset/gait_753/20250617_c1_a4_Take2/split_subjects/0/fit-smplx/smplx-params.npz\n",
      " -> Modified and saved to: mydataset/gait_753/20250617_c1_a4_Take2/split_subjects/0/fit-smplx/smplx-params_rotated.npz\n"
     ]
    }
   ],
   "source": [
    "rotate_smplx_params_y_180(\"mydataset/gait_753/20250617_c1_a4_Take2/split_subjects/0/fit-smplx/smplx-params.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
