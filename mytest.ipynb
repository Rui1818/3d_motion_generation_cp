{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d227889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from data_loaders.dataloader3d import get_dataloader, load_data, MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_root(data):\n",
    "    #only after frames have been cut\n",
    "    root = (data[0,8,:]+data[0, 9, :])/2\n",
    "    return data - root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_frames(data):\n",
    "    \"\"\"\n",
    "    Drop frames where all 25 rows are identical.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Array with shape (frames, 25, 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Filtered array with duplicate frames removed\n",
    "    \"\"\"\n",
    "    first_row = data[:, 0:1, :]  # Shape: (frames, 1, 5)\n",
    "    all_rows_same = np.all(data == first_row, axis=(1,2))\n",
    "\n",
    "    mask = ~all_rows_same\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf76a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"data_example/700/vitpose_c1_a4_2/vitpose/keypoints_3d/smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a98f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = load_data(\"mydataset\", split='train', keypointtype='6d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c4570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b422f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\n",
    "    dataset, \"train\", batch_size=2, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0a7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'data_loaders.dataloader3d.MotionDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of samples\n",
    "print(type(dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 135]) torch.Size([296, 135])\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0]\n",
    "print(img.shape, label.shape)  # shapes of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32bfde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([286, 72])\n",
      "torch.Size([215, 72])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(a[i].shape)\n",
    "print(b[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e740148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\", a[2].numpy().reshape(-1, 24, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50150eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations\\753\\vitpose_c1_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(96, 25, 5)\n",
      "observations\\753\\vitpose_c1_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(98, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(78, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(70, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(277, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(122, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(164, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(359, 25, 5)\n",
      "(286, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(182, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(72, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(58, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(139, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(166, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(221, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(48, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(144, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(215, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(273, 25, 5)\n",
      "Overall min and max values:\n",
      "-0.8759354218465447 0.975103836792062\n",
      "-0.022 1.2910989693513175\n",
      "-1.8723811722336592 1.8882560870466816\n"
     ]
    }
   ],
   "source": [
    "minx=5000\n",
    "maxx=-1000\n",
    "miny=5000\n",
    "maxy=-1000\n",
    "minz=5000\n",
    "maxz=-1000\n",
    "root=\"observations\"\n",
    "\n",
    "for patient in os.listdir(root):\n",
    "    for file in sorted(os.listdir(os.path.join(root, patient))):\n",
    "\n",
    "        mypath=os.path.join(root, patient, file)\n",
    "        mypath=os.path.join(mypath,\"vitpose\", \"keypoints_3d\", \"smpl-keypoints-3d_cut.npy\")\n",
    "        print(mypath)\n",
    "        data=np.load(mypath)\n",
    "        print(data.shape)   \n",
    "        data=drop_duplicate_frames(data)\n",
    "        print(data.shape)\n",
    "        datax=data[...,0]\n",
    "        datay=data[...,1]\n",
    "        dataz=data[...,2]\n",
    "        data=subtract_root(data)\n",
    "\n",
    "        curminx=np.min(datax)\n",
    "        curmaxx=np.max(datax)\n",
    "        curminy=np.min(datay)\n",
    "        curmaxy=np.max(datay)\n",
    "        curminz=np.min(dataz)\n",
    "        curmaxz=np.max(dataz)\n",
    "\n",
    "        if curminx < minx:\n",
    "            minx = curminx\n",
    "        if curmaxx > maxx:\n",
    "            maxx = curmaxx\n",
    "        if curminy < miny:\n",
    "            miny = curminy\n",
    "        if curmaxy > maxy:\n",
    "            maxy = curmaxy\n",
    "        if curminz < minz:\n",
    "            minz = curminz\n",
    "        if curmaxz > maxz:\n",
    "            maxz = curmaxz\n",
    "print(\"Overall min and max values:\")\n",
    "print(minx, maxx)\n",
    "print(miny, maxy)\n",
    "print(minz, maxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cfda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 25, 5)\n",
      "Keys inside: ['betas', 'global_orient', 'body_pose', 'transl', 'left_hand_pose', 'right_hand_pose', 'jaw_pose', 'leye_pose', 'reye_pose', 'expression']\n",
      "betas (53, 11)\n",
      "global_orient (53, 3)\n",
      "body_pose (53, 63)\n",
      "transl (53, 3)\n",
      "left_hand_pose (53, 12)\n",
      "right_hand_pose (53, 12)\n",
      "jaw_pose (53, 3)\n",
      "leye_pose (53, 3)\n",
      "reye_pose (53, 3)\n",
      "expression (53, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('mydataset/gait_753/20250617_c1_a2_Take1/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy')\n",
    "print(data.shape)\n",
    "data= np.load('mydataset/gait_753/20250617_c1_a2_Take1/split_subjects/0/fit-smplx/smplx-params.npz')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5f30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('0\\\\keypoints_3d\\\\smpl-keypoints-3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdef4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 25, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformation_sixd import smplx_to_6d, sixd_to_smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de05fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=smplx_to_6d(\"mydataset\\\\740\\\\20251002_c1_a1_Take1\\\\split_subjects\\\\0\\\\fit-smplx\\\\smplx-params.npz\", \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6185b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\utils\\utils_transform.py:54: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  rot_vec_3 = torch.cross(rot_vec_1, rot_vec_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing forward kinematics to calculate joint positions...\n",
      "Using generic SMPL-X model for forward kinematics.\n",
      "Extracting joints for 109 frames...\n",
      "\n",
      "Successfully reconstructed 3D keypoints.\n",
      "Output shape: (109, 22, 3)\n",
      "Saved result to: test/reconstructed_keypoints_3d_ref.npy\n"
     ]
    }
   ],
   "source": [
    "sixd_to_smplx(\"test/motion_6d_with_transl.npz\", \"test/\", \"smpl_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc0cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"012314.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9195c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 22, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_keypoints_only_mask(keypoints_path, height_thresh=0.03, vel_thresh=0.05, video_fps=30):\n",
    "    \"\"\"\n",
    "    Determines foot contact purely from kinematics (Keypoints), ignoring the Force Plate.\n",
    "    \n",
    "    Criteria for Contact:\n",
    "    1. Height: Joint Y-coordinate is close to the ground floor.\n",
    "    2. Velocity: Joint is not moving significantly (Stance phase is static).\n",
    "\n",
    "    Args:\n",
    "        keypoints_path (str): Path to .npy keypoints (frames, 25, 3).\n",
    "        height_thresh (float): Max distance from floor (e.g., 0.03m).\n",
    "        vel_thresh (float): Max velocity to be considered \"static\" (e.g., 0.05 m/frame).\n",
    "        video_fps (int): Video frame rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask of shape (frames, 25).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        keypoints = np.load(keypoints_path) # Shape (F, 25, 3)\n",
    "        n_frames = keypoints.shape[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Calculate the Floor (Ground Truth)\n",
    "    # We assume the lowest 5% of ALL foot points in the entire file represent the floor.\n",
    "    # This is robust to outliers.\n",
    "    foot_indices = [19, 20, 21, 22, 23, 24] # L/R BigToe, SmallToe, Heel\n",
    "    all_foot_y = keypoints[:, foot_indices, 1]\n",
    "    \n",
    "    # Filter out zeros (undetected points)\n",
    "    valid_y = all_foot_y[all_foot_y != 0]\n",
    "    if len(valid_y) == 0:\n",
    "        print(\"No valid foot keypoints found.\")\n",
    "        return np.zeros((n_frames, 25), dtype=int)\n",
    "        \n",
    "    floor_level = np.percentile(valid_y, 5) # 5th percentile is the estimated floor\n",
    "    print(f\"Auto-detected Floor Level: {floor_level:.4f}\")\n",
    "\n",
    "    velocity = np.linalg.norm(np.diff(keypoints, axis=0, prepend=keypoints[0:1]), axis=2)\n",
    "    \n",
    "    is_low = keypoints[:, :, 1] < (floor_level + height_thresh)\n",
    "\n",
    "    is_static = velocity < vel_thresh\n",
    "    \n",
    "    is_detected = keypoints[:, :, 1] != 0\n",
    "\n",
    "    contact_mask = is_low & is_static & is_detected\n",
    "\n",
    "    final_mask = np.zeros_like(contact_mask, dtype=int)\n",
    "    final_mask[:, foot_indices] = contact_mask[:, foot_indices].astype(int)\n",
    "\n",
    "    return final_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4686e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected Floor Level: 0.3254\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "path=\"mydataset/740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "mask = generate_keypoints_only_mask(path, height_thresh=0.03, vel_thresh=0.04)\n",
    "data=np.load(path)\n",
    "masked_data = data * mask[:, :, np.newaxis]\n",
    "np.save('masked_keypoints.npy', masked_data)\n",
    "print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4171b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"mydataset/gait_740/20251002_c1_a3_Take2/split_subjects/0/keypoints_3d/smpl-keypoints-3d.npy\"\n",
    "data=np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.delete(data, 1, axis=1)  # remove the second joint (index 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
