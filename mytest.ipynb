{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d227889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from data_loaders.dataloader3d import get_dataloader, load_data, MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_root(data):\n",
    "    #only after frames have been cut\n",
    "    root = (data[0,8,:]+data[0, 9, :])/2\n",
    "    return data - root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_frames(data):\n",
    "    \"\"\"\n",
    "    Drop frames where all 25 rows are identical.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Array with shape (frames, 25, 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Filtered array with duplicate frames removed\n",
    "    \"\"\"\n",
    "    first_row = data[:, 0:1, :]  # Shape: (frames, 1, 5)\n",
    "    all_rows_same = np.all(data == first_row, axis=(1,2))\n",
    "\n",
    "    mask = ~all_rows_same\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf76a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"data_example/700/vitpose_c1_a4_2/vitpose/keypoints_3d/smpl-keypoints-3d_cut.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a98f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = load_data(\"mydataset\", split='train', keypointtype='6d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c4570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionDataset(\n",
    "    \"gait\",\n",
    "    a,\n",
    "    b,\n",
    "    input_motion_length=296,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b422f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\n",
    "    dataset, \"train\", batch_size=2, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0a7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'data_loaders.dataloader3d.MotionDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of samples\n",
    "print(type(dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 135]) torch.Size([296, 135])\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0]\n",
    "print(img.shape, label.shape)  # shapes of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32bfde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([286, 72])\n",
      "torch.Size([215, 72])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(a[i].shape)\n",
    "print(b[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e740148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\", a[2].numpy().reshape(-1, 24, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50150eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations\\753\\vitpose_c1_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(96, 25, 5)\n",
      "observations\\753\\vitpose_c1_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(98, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(78, 25, 5)\n",
      "observations\\753\\vitpose_c1_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(70, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(277, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(195, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(122, 25, 5)\n",
      "observations\\753\\vitpose_c1_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(164, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(359, 25, 5)\n",
      "(286, 25, 5)\n",
      "observations\\753\\vitpose_c1_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(182, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(72, 25, 5)\n",
      "observations\\753\\vitpose_c2_a1_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(58, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a2_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(63, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(420, 25, 5)\n",
      "(139, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(166, 25, 5)\n",
      "observations\\753\\vitpose_c2_a3_3\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(419, 25, 5)\n",
      "(221, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(239, 25, 5)\n",
      "(48, 25, 5)\n",
      "observations\\753\\vitpose_c2_a4_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(240, 25, 5)\n",
      "(144, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(215, 25, 5)\n",
      "observations\\753\\vitpose_c2_a5_2\\vitpose\\keypoints_3d\\smpl-keypoints-3d_cut.npy\n",
      "(360, 25, 5)\n",
      "(273, 25, 5)\n",
      "Overall min and max values:\n",
      "-0.8759354218465447 0.975103836792062\n",
      "-0.022 1.2910989693513175\n",
      "-1.8723811722336592 1.8882560870466816\n"
     ]
    }
   ],
   "source": [
    "minx=5000\n",
    "maxx=-1000\n",
    "miny=5000\n",
    "maxy=-1000\n",
    "minz=5000\n",
    "maxz=-1000\n",
    "root=\"observations\"\n",
    "\n",
    "for patient in os.listdir(root):\n",
    "    for file in sorted(os.listdir(os.path.join(root, patient))):\n",
    "\n",
    "        mypath=os.path.join(root, patient, file)\n",
    "        mypath=os.path.join(mypath,\"vitpose\", \"keypoints_3d\", \"smpl-keypoints-3d_cut.npy\")\n",
    "        print(mypath)\n",
    "        data=np.load(mypath)\n",
    "        print(data.shape)   \n",
    "        data=drop_duplicate_frames(data)\n",
    "        print(data.shape)\n",
    "        datax=data[...,0]\n",
    "        datay=data[...,1]\n",
    "        dataz=data[...,2]\n",
    "        data=subtract_root(data)\n",
    "\n",
    "        curminx=np.min(datax)\n",
    "        curmaxx=np.max(datax)\n",
    "        curminy=np.min(datay)\n",
    "        curmaxy=np.max(datay)\n",
    "        curminz=np.min(dataz)\n",
    "        curmaxz=np.max(dataz)\n",
    "\n",
    "        if curminx < minx:\n",
    "            minx = curminx\n",
    "        if curmaxx > maxx:\n",
    "            maxx = curmaxx\n",
    "        if curminy < miny:\n",
    "            miny = curminy\n",
    "        if curmaxy > maxy:\n",
    "            maxy = curmaxy\n",
    "        if curminz < minz:\n",
    "            minz = curminz\n",
    "        if curmaxz > maxz:\n",
    "            maxz = curmaxz\n",
    "print(\"Overall min and max values:\")\n",
    "print(minx, maxx)\n",
    "print(miny, maxy)\n",
    "print(minz, maxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cfda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys inside: ['betas', 'global_orient', 'body_pose', 'transl', 'left_hand_pose', 'right_hand_pose', 'jaw_pose', 'leye_pose', 'reye_pose', 'expression']\n",
      "betas (88, 11)\n",
      "global_orient (88, 3)\n",
      "body_pose (88, 63)\n",
      "transl (88, 3)\n",
      "left_hand_pose (88, 12)\n",
      "right_hand_pose (88, 12)\n",
      "jaw_pose (88, 3)\n",
      "leye_pose (88, 3)\n",
      "reye_pose (88, 3)\n",
      "expression (88, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('0\\\\fit-smplx\\\\smplx-params.npz')\n",
    "\n",
    "print(\"Keys inside:\", data.files)\n",
    "for k in data.files:\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5f30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('0\\\\keypoints_3d\\\\smpl-keypoints-3d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdef4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 25, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformation_sixd import smplx_to_6d, sixd_to_smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de05fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=smplx_to_6d(\"mydataset\\\\740\\\\20251002_c1_a1_Take1\\\\split_subjects\\\\0\\\\fit-smplx\\\\smplx-params.npz\", \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6185b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rui\\Vorlesungskript\\Master\\Thesis\\Thesis_project\\utils\\utils_transform.py:54: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  rot_vec_3 = torch.cross(rot_vec_1, rot_vec_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing forward kinematics to calculate joint positions...\n",
      "Using generic SMPL-X model for forward kinematics.\n",
      "Extracting joints for 109 frames...\n",
      "\n",
      "Successfully reconstructed 3D keypoints.\n",
      "Output shape: (109, 22, 3)\n",
      "Saved result to: test/reconstructed_keypoints_3d_ref.npy\n"
     ]
    }
   ],
   "source": [
    "sixd_to_smplx(\"test/motion_6d_with_transl.npz\", \"test/\", \"smpl_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc0cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"test/motion_6d_with_transl.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08ad5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8399562 ,  0.00595307, -1.8214412 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transl'][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59aa22a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66853815,  0.02578962, -1.5105556 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transl'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdeefb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor(data['transl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f438d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=t[...,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe00267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([109, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47b5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.randn(1, 296, 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f8ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 296, 132])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=test[:,:, :3]\n",
    "test2=test[:,:, 3:]\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f5ec778",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rot = torch.mean(\n",
    "    torch.norm(\n",
    "        (test2).reshape(-1, 6),\n",
    "        2,\n",
    "        1,\n",
    "    )\n",
    ")\n",
    "\n",
    "loss_transl = torch.mean(\n",
    "    torch.norm(\n",
    "        (test1).reshape(-1, 3),\n",
    "        2,\n",
    "        1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b986091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3417)\n",
      "tensor(1.6114)\n"
     ]
    }
   ],
   "source": [
    "print(loss_rot)\n",
    "print(loss_transl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9570582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.5594)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_my = torch.mean(\n",
    "    torch.norm(\n",
    "        (test).reshape(-1, 135),\n",
    "        2,\n",
    "        1,\n",
    "    )\n",
    ")\n",
    "loss_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab4858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 132)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['motion_6d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beacf061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'betas' in data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
